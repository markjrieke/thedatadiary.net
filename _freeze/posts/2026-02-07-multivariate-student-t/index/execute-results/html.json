{
  "hash": "a30087ce260a388537eb2571d23e430a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"What's the tea, sis?\"\ndate: '2026-02-07'\ncategories: [stan]\ndescription: \"A reparameterization of the multivariate student-t distribution in Stan\"\nimage: header.png\n---\n\nA few years ago, a colleague and I were working on implementing the [multivariate student-t](https://en.wikipedia.org/wiki/Multivariate_t-distribution) distribution as a part of a new model. We were looking to implement the [non-centered](https://mc-stan.org/docs/stan-users-guide/efficiency-tuning.html#reparameterization.section) parameterization. Luckily enough, Andre Pfeuffer had [shared the following solution on the Stan forums](https://discourse.mc-stan.org/t/non-centered-parameterization-of-the-multivariate-student-t-distribution/4176/8) that rewrites the multivariate student-t in terms of inverse Chi-Square distribution:\n\n```stan\ndata {\n  int<lower=1> p;\n  vector[p] mu;\n  cholesky_factor_cov[p,p] L;\n  real<lower=0> nu;\n}\nparameters {\n  vector[p] z;\n  real<lower=0> u;\n}\ntransformed parameters {\n  vector[p] x;\n  x = mu + sqrt(nu / u) * (L * z); // distributed multi_student_t\n}\nmodel {\n  target += normal_lpdf(z | 0, 1);\n  target += chi_square_lpdf(u | nu);\n}\n```\n\nThis works well! But! This parameterization requires that you pass in the degrees of freedom, $\\nu$, as data.^[You could technically simply model $\\nu$ as a parameter with this specification, but then you end up with a centered prior over $u$, which defeats the purpose of implementing a non-centered parameterization.] If you instead want to estimate $\\nu$ as a part of fitting the model, you'll need an alternative parameterization.\n\nLuckily enough for you, dear reader, I've done this work for you. If you want to skip the derivation and get straight to estimating, you can plop this function into your Stan model. What follows below is the derivation [that I shared with the Stan forums.](https://discourse.mc-stan.org/t/non-centered-parameterization-of-the-multivariate-student-t-distribution/4176/9)\n\n```stan\nreal multivariate_t_scale_lpdf(vector x,\n                               real nu) {\n    int N = size(x);\n    vector[N] xx = nu/(x^2);\n    real lp = 0.0;\n    for (n in 1:N) {\n        lp += log(2) + log(nu) + chi_square_lpdf(xx[n] | nu) - 3*log(x[n]);\n    }\n    return lp;\n}\n```\n\n## Deriving a multivariate student-t\n\nThe goal is to replace `sqrt(nu / u)` in Andre's original solution with a new scale parameter, $x$, and derive some density function for $x$ that takes $\\nu$ as an input. From some tinkering, I found that the quantile function for the outcome of interest is\n\n$$\nx = \\sqrt{\\frac{\\nu}{\\mathcal{Q}(1-p,\\nu)}}\n$$\n\nwhere $\\mathcal{Q}$ is the quantile function of the Chi-Square distribution.\n\nI didn't exactly derive this quantile function robustly --- it was a game of \"guess and check.\" If I simulate the outcome of interest, then compare the **<span style='color:royalblue'>quantile distribution of the simulated values</span>** against my **derived quantile distribution**, the results line up well enough for me to say that this is the right function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(riekelib)\n\n# simulate outcome w/df = 7\nnu <- 7\nraw <- sqrt(nu/rchisq(1e4, nu))\n\n# quantiles for checking simulated results against empirical\nsim <- \n  tibble(p = seq(from = 0, to = 1, length.out = 100),\n         q = quantile(raw, probs = seq(from = 0, to = 1, length.out = 100)))\n\n# check the quantile function\ntibble(p = seq(from = 0, to = 1, length.out = 1000)) %>%\n  mutate(q = sqrt(nu/qchisq(1 - p, nu))) %>%\n  ggplot(aes(x = p,\n             y = q)) + \n  geom_line() +\n  geom_point(data = sim,\n             color = \"royalblue\") +\n  theme_rieke()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=2700}\n:::\n:::\n\n\nWe want to get $p$ on its own so that we can eventually derive a density, $d$. Some rearranging yields the following:\n\n$$\n\\mathcal{Q}(1-p,\\nu) = \\frac{\\nu}{x^2}\n$$\n\nSetting $a=\\frac{\\nu}{x^2}$ and recalling that the quantile and cumulative functions are inverses lets us solve for $p$ explicitly. Here, $\\mathcal{C}$ is the cumulative distribution function for the Chi-Square distribution --- this gives us a cumulative distribution function for $x$.\n\n$$\n\\begin{align*}\n\\mathcal{C}(a,\\nu) &= 1-p \\\\\np &= 1 - \\mathcal{C}(a,\\nu)\n\\end{align*}\n$$\n\nThe density function is just the derivative of the CDF, so by virtue of the chain rule, we get the following if we take the derivative of our CDF with respect to $x$:\n\n$$\nd = -\\mathcal{D}(a,\\nu) \\times a'\n$$\n\nwhere $\\mathcal{D}$ is the density function of the Chi-Square distribution and $a'$ is the derivative of $a$ with respect to $x$.\n\nSub in $\\frac{\\nu}{x^2}$ for our temporary variable, $a$, finish out the derivative, do some simplification, and voila! A density function for the multivariate student-t scale drops out!\n\n$$\nd = \\mathcal{D}\\left(\\frac{\\nu}{x^2},\\nu\\right)\\left(\\frac{2\\nu}{x^3}\\right)\n$$\nComparing the **<span style='color:royalblue'>empirical density of the simulated values</span>** against the **derived density function** again yields an overlap that is, to me, good enough to call correct.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate outcome w/df = 7\nnu <- 7\nraw <- sqrt(nu/rchisq(1e4, nu))\n\ntibble(x = seq(from = 0, to = 6, length.out = 1000)) %>%\n  mutate(d = dchisq(nu/(x^2), nu) * (2*nu)/(x^3)) %>%\n  ggplot(aes(x = x)) + \n  geom_line(aes(y = d)) +\n  geom_density(data = tibble(x = raw),\n               color = \"royalblue\") +\n  theme_rieke()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=2700}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}