<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>workboots on the data diary</title>
    <link>https://www.thedatadiary.net/categories/workboots/</link>
    <description>Recent content in workboots on the data diary</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Mark Rieke {year}</copyright>
    <lastBuildDate>Tue, 05 Jul 2022 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://www.thedatadiary.net/categories/workboots/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The Math Behind workboots</title>
      <link>https://www.thedatadiary.net/blog/2022-07-05-the-math-behind-workboots/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.thedatadiary.net/blog/2022-07-05-the-math-behind-workboots/</guid>
      <description>


&lt;p&gt;Generating prediction intervals with workboots hinges on a few core concepts: bootstrap resampling, estimating prediction error for each resample, and aggregating the resampled prediction errors for each observation. The &lt;a href=&#34;https://rsample.tidymodels.org/reference/bootstraps.html&#34;&gt;&lt;code&gt;bootstraps()&lt;/code&gt; documentation from {rsample}&lt;/a&gt; gives a concise definition of bootstrap resampling:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A bootstrap sample is a sample that is the same size as the original data set that is made using replacement. This results in analysis samples that have multiple replicates of some of the original rows of the data. The assessment set is defined as the rows of the original data that were not included in the bootstrap sample. This is often referred to as the “out-of-bag” (OOB) sample.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This vignette will walk through the details of estimating and aggregating prediction errors — additional resources can be found in Davison and Hinkley’s book, &lt;a href=&#34;https://www.cambridge.org/core/books/bootstrap-methods-and-their-application/ED2FD043579F27952363566DC09CBD6A&#34;&gt;&lt;em&gt;Bootstrap Methods and their Application&lt;/em&gt;&lt;/a&gt;, or Efron and Tibshirani’s paper, &lt;a href=&#34;https://www.jstor.org/stable/2965703&#34;&gt;&lt;em&gt;Improvements on Cross-Validation: The Bootstrap .632+ Method&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;the-bootstrap-.632-method&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Bootstrap .632+ Method&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;What follows here is largely a summary of &lt;a href=&#34;https://stats.stackexchange.com/questions/96739/what-is-the-632-rule-in-bootstrapping/96750#96750&#34;&gt;this explanation&lt;/a&gt; of the .632+ error rate by Benjamin Deonovic.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When working with bootstrap resamples of a dataset, there are two error estimates we can work with: the bootstrap training error and the out-of-bag (oob) error. Using the &lt;a href=&#34;https://modeldata.tidymodels.org/reference/Sacramento.html&#34;&gt;Sacramento housing dataset&lt;/a&gt;, we can estimate the training and oob error for a single bootstrap.&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;sacramento_boots
#&amp;gt; # Bootstrap sampling 
#&amp;gt; # A tibble: 1 × 2
#&amp;gt;   splits            id        
#&amp;gt;   &amp;lt;list&amp;gt;            &amp;lt;chr&amp;gt;     
#&amp;gt; 1 &amp;lt;split [699/261]&amp;gt; Bootstrap1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using a &lt;a href=&#34;https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#k-NN_regression&#34;&gt;k-nearest-neighbor regression model&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Root-mean-square_deviation#:~:text=The%20root%2Dmean%2Dsquare%20deviation,estimator%20and%20the%20values%20observed.&#34;&gt;rmse&lt;/a&gt; as our error metric, we find that the training and oob error differ, with the training error lesser than the oob error.&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;sacramento_train_err
#&amp;gt; [1] 0.08979873
sacramento_oob_err
#&amp;gt; [1] 0.1661675&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The training error is overly optimistic in the model’s performance and likely to under-estimate the prediction error. We are interested in the model’s performance on new data. The oob error, on the other hand, is likely to over-estimate the prediction error! This is due to non-distinct observations in the bootstrap sample that results from sampling with replacement. Given that &lt;a href=&#34;https://stats.stackexchange.com/questions/88980/why-on-average-does-each-bootstrap-sample-contain-roughly-two-thirds-of-observat?lq=1&#34;&gt;the average number of distinct observations in a bootstrap training set is about &lt;code&gt;0.632 * total_observations&lt;/code&gt;&lt;/a&gt;, Efron and Tibshirani proposed a blend of the training and oob error with the 0.632 estimate:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
Err_{.632} &amp;amp; = 0.368 Err_{train} + 0.632 Err_{oob}
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;sacramento_632 &amp;lt;- 0.368 * sacramento_train_err + 0.632 * sacramento_oob_err
sacramento_632
#&amp;gt; [1] 0.1380638&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If, however, the model is highly overfit to the bootstrap training set, the training error will approach 0 and the 0.632 estimate will &lt;em&gt;under estimate&lt;/em&gt; the prediction error.&lt;/p&gt;
&lt;p&gt;An example from &lt;a href=&#34;http://appliedpredictivemodeling.com/&#34;&gt;&lt;em&gt;Applied Predictive Modeling&lt;/em&gt;&lt;/a&gt; shows that as model complexity increases, the reported resample accuracy by the 0.632 estimate continues to increase whereas other resampling strategies report diminishing returns:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/5731043/157986232-9c32c1c2-a7ed-4f9f-b28e-7d8ccb7ac41c.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As an alternative to the 0.632 estimate, Efron &amp;amp; Tibshirani also propose the 0.632+ estimate, which re-weights the blend of training and oob error based on the model overfit rate:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
Err_{0.632+} &amp;amp; = (1 - w) Err_{train} + w Err_{oob} \\
\\
w &amp;amp; = \frac{0.632}{1 - 0.368 R} \\
\\
R &amp;amp; = \frac{Err_{oob} - Err_{train}}{\gamma - Err_{train}}
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; represents the overfit rate and &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the no-information error rate, estimated by evaulating all combinations of predictions and actual values in the bootstrap training set.&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;sacramento_632_plus &amp;lt;- (1 - w) * sacramento_train_err + w * sacramento_oob_err
sacramento_632_plus
#&amp;gt; [1] 0.1450502&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When there is no overfitting (i.e., &lt;span class=&#34;math inline&#34;&gt;\(R = 0\)&lt;/span&gt;) the 0.632+ estimate will equal the 0.632 estimate. In this case, however, the model is overfitting the training set and the 0.632+ error estimate is pushed a bit closer to the oob error.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prediction-intervals-with-many-bootstraps&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prediction intervals with many bootstraps&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Root-mean-square_deviation#Formula&#34;&gt;For an unbiased estimator, rmse is the standard deviation of the residuals&lt;/a&gt;. With this in mind, we can modify our predictions to include a sample from the residual distribution (for more information, see Algorithm 6.4 from Davison and Hinkley’s &lt;em&gt;Bootstrap Methods and their Application&lt;/em&gt;):&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;set.seed(999)
resid_train_add &amp;lt;- rnorm(length(preds_train), 0, sacramento_632_plus)
preds_train_mod &amp;lt;- preds_train + resid_train_add&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus far, we’ve been working with a single bootstrap resample. When working with a single bootstrap resample, adding this residual term gives a pretty poor estimate for each observation:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-07-05-the-math-behind-workboots/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With workboots, however, we can repeat this process over many bootstrap datasets to generate a prediction distribution for each observation:&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;library(workboots)
# fit and predict price in sacramento_test from 100 models
# the default number of resamples is 2000 - dropping here to speed up knitting
set.seed(555)
sacramento_pred_int &amp;lt;-
  sacramento_wf %&amp;gt;%
  predict_boots(
    n = 100,
    training_data = sacramento_train,
    new_data = sacramento_test
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-07-05-the-math-behind-workboots/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This methodology produces prediction distributions that are &lt;a href=&#34;https://markjrieke.github.io/workboots/articles/Estimating-Linear-Intervals.html&#34;&gt;consistent with what we might expect from linear models&lt;/a&gt; while making no assumptions about model type (i.e., we can use a non-parametric model; in this case, a k-nearest neighbors regression).&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introducing {workboots}</title>
      <link>https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/</link>
      <pubDate>Mon, 14 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/</guid>
      <description>
&lt;script src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Sometimes, we want a model that generates a range of possible outcomes around each prediction and may opt for a model that can generate a prediction interval, like a linear model. Other times, we just care about point predictions and may opt to use a more powerful model like XGBoost. But what if we want the best of both worlds: getting a range of predictions while still using a powerful model? That’s where &lt;a href=&#34;https://github.com/markjrieke/workboots&#34;&gt;&lt;code&gt;{workboots}&lt;/code&gt;&lt;/a&gt; comes to the rescue! &lt;code&gt;{workboots}&lt;/code&gt; uses bootstrap resampling to train many models which can be used to generate a range of outcomes — regardless of model type.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;pics/workboots.PNG&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;installation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Installation&lt;/h3&gt;
&lt;p&gt;Version 0.1.0 of &lt;code&gt;{workboots}&lt;/code&gt; is available on &lt;a href=&#34;https://cran.r-project.org/web/packages/workboots/index.html&#34;&gt;CRAN&lt;/a&gt;. Given that the package is still in early development, however, I’d recommend installing the development version from &lt;a href=&#34;https://github.com/markjrieke/workboots&#34;&gt;github&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install from CRAN
install.packages(&amp;quot;workboots&amp;quot;)

# or install the development version
devtools::install_github(&amp;quot;markjrieke/workboots&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;usage&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Usage&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;{workboots}&lt;/code&gt; builds on top of the &lt;a href=&#34;https://www.tidymodels.org/&#34;&gt;&lt;code&gt;{tidymodels}&lt;/code&gt;&lt;/a&gt; suite of packages and is intended to be used in conjunction with a &lt;a href=&#34;https://workflows.tidymodels.org/&#34;&gt;tidymodel workflow&lt;/a&gt;. Teaching how to use &lt;code&gt;{tidymodels}&lt;/code&gt; is beyond the scope of this post, but some helpful resources are linked at the bottom for further exploration.&lt;/p&gt;
&lt;p&gt;We’ll walk through two examples that show the benefit of the package: estimating a linear model’s prediction interval and generating a prediction interval for a boosted tree model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-a-prediction-interval&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Estimating a prediction interval&lt;/h3&gt;
&lt;p&gt;Let’s get started with a model we know can generate a prediction interval: a basic linear model. In this example, we’ll use the &lt;a href=&#34;https://modeldata.tidymodels.org/reference/ames.html&#34;&gt;Ames housing dataset&lt;/a&gt; to predict a home’s price based on its square footage.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidymodels)

# setup our data
data(&amp;quot;ames&amp;quot;)
ames_mod &amp;lt;- ames %&amp;gt;% select(First_Flr_SF, Sale_Price)

# relationship between square footage and price
ames_mod %&amp;gt;%
  ggplot(aes(x = First_Flr_SF, y = Sale_Price)) +
  geom_point(alpha = 0.25) +
  scale_y_continuous(labels = scales::dollar_format(), trans = &amp;quot;log10&amp;quot;) +
  scale_x_continuous(labels = scales::comma_format(), trans = &amp;quot;log10&amp;quot;) +
  labs(title = &amp;quot;Relationship between Square Feet and Sale Price&amp;quot;,
       subtitle = &amp;quot;Linear relationship between the log transforms of square footage and price&amp;quot;,
       x = NULL,
       y = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can use a linear model to predict the log transform of &lt;code&gt;Sale_Price&lt;/code&gt; based on the log transform of &lt;code&gt;First_Flr_SF&lt;/code&gt;. In this example, we’ll train a linear model then plot our predictions against a holdout set with a prediction interval.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# log transform
ames_mod &amp;lt;- 
  ames_mod %&amp;gt;%
  mutate(across(everything(), log10))

# split into train/test data
set.seed(918)
ames_split &amp;lt;- initial_split(ames_mod)
ames_train &amp;lt;- training(ames_split)
ames_test &amp;lt;- testing(ames_split)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# train a linear model
set.seed(314)
mod &amp;lt;- lm(Sale_Price ~ First_Flr_SF, data = ames_train)

# predict on new data with a prediction interval
ames_preds &amp;lt;-
  mod %&amp;gt;%
  predict(ames_test, interval = &amp;quot;predict&amp;quot;) %&amp;gt;%
  as_tibble()

# plot!
ames_preds %&amp;gt;%
  
  # re-scale predictions to match the original dataset&amp;#39;s scale
  bind_cols(ames_test) %&amp;gt;%
  mutate(across(everything(), ~10^.x)) %&amp;gt;%
  
  # add geoms
  ggplot(aes(x = First_Flr_SF)) +
  geom_point(aes(y = Sale_Price),
             alpha = 0.25) +
  geom_line(aes(y = fit),
            size = 1) +
  geom_ribbon(aes(ymin = lwr,
                  ymax = upr),
              alpha = 0.25) +
  scale_y_continuous(labels = scales::dollar_format(), trans = &amp;quot;log10&amp;quot;) +
  scale_x_continuous(labels = scales::comma_format(), trans = &amp;quot;log10&amp;quot;) +
  labs(title = &amp;quot;Linear Model of Sale Price predicted by Square Footage&amp;quot;,
       subtitle = &amp;quot;Shaded area represents the 95% prediction interval&amp;quot;,
       x = NULL,
       y = NULL) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;{workboots}&lt;/code&gt;, we can approximate the linear model’s prediction interval by passing a workflow built on a linear model to the function &lt;code&gt;predict_boots()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidymodels)
library(workboots)

# setup a workflow with a linear model
ames_wf &amp;lt;-
  workflow() %&amp;gt;%
  add_recipe(recipe(Sale_Price ~ First_Flr_SF, data = ames_train)) %&amp;gt;%
  add_model(linear_reg())

# generate bootstrap predictions on ames_test
set.seed(713)
ames_preds_boot &amp;lt;-
  ames_wf %&amp;gt;%
  predict_boots(
    n = 2000,
    training_data = ames_train,
    new_data = ames_test
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;predict_boots()&lt;/code&gt; works by creating 2000 &lt;a href=&#34;https://rsample.tidymodels.org/reference/bootstraps.html&#34;&gt;bootstrap resamples&lt;/a&gt; of the training data, fitting a linear model to each resample, then generating 2000 predictions for each home’s price in the holdout set. We can then use &lt;code&gt;summarise_predictions()&lt;/code&gt; to generate upper and lower intervals for each prediction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_preds_boot %&amp;gt;%
  summarise_predictions()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 733 x 5
##    rowid .preds               .pred_lower .pred .pred_upper
##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;                     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
##  1     1 &amp;lt;tibble [2,000 x 2]&amp;gt;        5.17  5.44        5.71
##  2     2 &amp;lt;tibble [2,000 x 2]&amp;gt;        4.98  5.27        5.55
##  3     3 &amp;lt;tibble [2,000 x 2]&amp;gt;        4.97  5.25        5.52
##  4     4 &amp;lt;tibble [2,000 x 2]&amp;gt;        5.12  5.40        5.67
##  5     5 &amp;lt;tibble [2,000 x 2]&amp;gt;        5.15  5.44        5.71
##  6     6 &amp;lt;tibble [2,000 x 2]&amp;gt;        4.93  5.21        5.49
##  7     7 &amp;lt;tibble [2,000 x 2]&amp;gt;        4.67  4.94        5.22
##  8     8 &amp;lt;tibble [2,000 x 2]&amp;gt;        4.85  5.13        5.40
##  9     9 &amp;lt;tibble [2,000 x 2]&amp;gt;        4.87  5.14        5.41
## 10    10 &amp;lt;tibble [2,000 x 2]&amp;gt;        5.14  5.41        5.69
## # ... with 723 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By overlaying the intervals on top of one another, we can see that the prediction interval generated by &lt;code&gt;predict_boots()&lt;/code&gt; is a good approximation of the theoretical interval generated by &lt;code&gt;lm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_preds_boot %&amp;gt;%
  summarise_predictions() %&amp;gt;%
  bind_cols(ames_preds) %&amp;gt;%
  bind_cols(ames_test) %&amp;gt;%
  mutate(across(c(.pred_lower:Sale_Price), ~10^.x)) %&amp;gt;%
  ggplot(aes(x = First_Flr_SF)) +
  geom_point(aes(y = Sale_Price),
             alpha = 0.25) +
  geom_line(aes(y = fit),
            size = 1) +
  geom_ribbon(aes(ymin = lwr,
                  ymax = upr),
              alpha = 0.25) +
  geom_point(aes(y = .pred),
             color = &amp;quot;blue&amp;quot;,
             alpha = 0.25) +
  geom_errorbar(aes(ymin = .pred_lower,
                    ymax = .pred_upper),
                color = &amp;quot;blue&amp;quot;,
                alpha = 0.25,
                width = 0.0125) +
  scale_y_continuous(labels = scales::dollar_format(), trans = &amp;quot;log10&amp;quot;) +
  scale_x_continuous(labels = scales::comma_format(), trans = &amp;quot;log10&amp;quot;) +
  labs(title = &amp;quot;Linear Model of Sale Price predicted by Square Footage&amp;quot;,
       subtitle = &amp;quot;Bootstrap prediction interval closely matches theoretical prediction interval&amp;quot;,
       x = NULL,
       y = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both &lt;code&gt;lm()&lt;/code&gt; and &lt;code&gt;summarise_predictions()&lt;/code&gt; use a 95% prediction interval by default but we can generate other intervals by passing different values to the parameter &lt;code&gt;conf&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_preds_boot %&amp;gt;%
  
  # generate 95% prediction interval
  summarise_predictions(conf = 0.95) %&amp;gt;%
  rename(.pred_lower_95 = .pred_lower,
         .pred_upper_95 = .pred_upper) %&amp;gt;%
  select(-.pred) %&amp;gt;%
  
  # generate 80% prediction interval
  summarise_predictions(conf = 0.80) %&amp;gt;%
  rename(.pred_lower_80 = .pred_lower,
         .pred_upper_80 = .pred_upper) %&amp;gt;%
  bind_cols(ames_test) %&amp;gt;%
  mutate(across(c(.pred_lower_95:Sale_Price), ~10^.x)) %&amp;gt;%
  
  # plot!
  ggplot(aes(x = First_Flr_SF)) +
  geom_point(aes(y = Sale_Price),
             alpha = 0.25) +
  geom_line(aes(y = .pred),
            size = 1,
            color = &amp;quot;blue&amp;quot;) +
  geom_ribbon(aes(ymin = .pred_lower_95,
                  ymax = .pred_upper_95),
              alpha = 0.25,
              fill = &amp;quot;blue&amp;quot;) +
  geom_ribbon(aes(ymin = .pred_lower_80,
                  ymax = .pred_upper_80),
              alpha = 0.25,
              fill = &amp;quot;blue&amp;quot;) +
  scale_y_continuous(labels = scales::dollar_format(), trans = &amp;quot;log10&amp;quot;) +
  scale_x_continuous(labels = scales::comma_format(), trans = &amp;quot;log10&amp;quot;) +
  labs(title = &amp;quot;Linear Model of Sale Price predicted by Square Footage&amp;quot;,
       subtitle = &amp;quot;Predictions alongside 95% and 80% bootstrap prediction interval&amp;quot;,
       x = NULL,
       y = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this example shows, &lt;code&gt;{workboots}&lt;/code&gt; can approximate linear prediction intervals pretty well! But this isn’t very useful, since we can just generate a linear prediction interval from a linear model directly. The real benefit of &lt;code&gt;{workboots}&lt;/code&gt; comes from generating prediction intervals from &lt;em&gt;any&lt;/em&gt; model!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bootstrap-prediction-intervals-with-non-linear-models&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bootstrap prediction intervals with non-linear models&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://xgboost.readthedocs.io/en/stable/&#34;&gt;XGBoost&lt;/a&gt; is one of my favorite models. Up until now, however, in situations that require a prediction interval, I’ve had to opt for a simpler model. With &lt;code&gt;{workboots}&lt;/code&gt;, that’s no longer an issue! In this example, we’ll use XGBoost and &lt;code&gt;{workboots}&lt;/code&gt; to generate predictions of a penguins weight from the &lt;a href=&#34;https://modeldata.tidymodels.org/reference/penguins.html&#34;&gt;Palmer Penguins dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started, let’s build a workflow and train an individual model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load and prep data
data(&amp;quot;penguins&amp;quot;)

penguins &amp;lt;-
  penguins %&amp;gt;%
  drop_na()

# split data into training and testing sets
set.seed(123)
penguins_split &amp;lt;- initial_split(penguins)
penguins_test &amp;lt;- testing(penguins_split)
penguins_train &amp;lt;- training(penguins_split)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a workflow
penguins_wf &amp;lt;-
  workflow() %&amp;gt;%
  
  # add preprocessing steps
  add_recipe(
    recipe(body_mass_g ~ ., data = penguins_train) %&amp;gt;%
      step_dummy(all_nominal_predictors()) 
  ) %&amp;gt;%
  
  # add xgboost model spec
  add_model(
    boost_tree(&amp;quot;regression&amp;quot;)
  )

# fit to training data &amp;amp; predict on test data
set.seed(234)
penguins_preds &amp;lt;-
  penguins_wf %&amp;gt;%
  fit(penguins_train) %&amp;gt;%
  predict(penguins_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As mentioned above, XGBoost models can only generate point predictions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins_preds %&amp;gt;%
  bind_cols(penguins_test) %&amp;gt;%
  ggplot(aes(x = body_mass_g,
             y = .pred)) +
  geom_point() +
  geom_abline(linetype = &amp;quot;dashed&amp;quot;,
              color = &amp;quot;gray&amp;quot;) +
  labs(title = &amp;quot;XGBoost Model of Penguin Weight&amp;quot;,
       subtitle = &amp;quot;Individual model can only output individual predictions&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;{workboots}&lt;/code&gt;, however, we can generate a prediction interval from our XGBoost model for each penguin’s weight!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create 2000 models from bootstrap resamples and make predictions on the test set
set.seed(345)
penguins_preds_boot &amp;lt;-
  penguins_wf %&amp;gt;%
  predict_boots(
    n = 2000,
    training_data = penguins_train,
    new_data = penguins_test
  )

penguins_preds_boot %&amp;gt;%
  summarise_predictions()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 84 x 5
##    rowid .preds               .pred_lower .pred .pred_upper
##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;                     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
##  1     1 &amp;lt;tibble [2,000 x 2]&amp;gt;       2788. 3470.       4136.
##  2     2 &amp;lt;tibble [2,000 x 2]&amp;gt;       2838. 3534.       4231.
##  3     3 &amp;lt;tibble [2,000 x 2]&amp;gt;       2942. 3598.       4301.
##  4     4 &amp;lt;tibble [2,000 x 2]&amp;gt;       3354. 4158.       4889.
##  5     5 &amp;lt;tibble [2,000 x 2]&amp;gt;       3186. 3870.       4500.
##  6     6 &amp;lt;tibble [2,000 x 2]&amp;gt;       2884. 3519.       4208.
##  7     7 &amp;lt;tibble [2,000 x 2]&amp;gt;       2790. 3434.       4094.
##  8     8 &amp;lt;tibble [2,000 x 2]&amp;gt;       3394. 4071.       4772.
##  9     9 &amp;lt;tibble [2,000 x 2]&amp;gt;       2812. 3447.       4096.
## 10    10 &amp;lt;tibble [2,000 x 2]&amp;gt;       2744. 3404.       4063.
## # ... with 74 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How does our bootstrap model perform?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins_preds_boot %&amp;gt;%
  summarise_predictions() %&amp;gt;%
  bind_cols(penguins_test) %&amp;gt;%
  ggplot(aes(x = body_mass_g,
             y = .pred,
             ymin = .pred_lower,
             ymax = .pred_upper)) +
  geom_abline(linetype = &amp;quot;dashed&amp;quot;,
              color = &amp;quot;gray&amp;quot;) +
  geom_errorbar(alpha = 0.5,
                color = &amp;quot;blue&amp;quot;) +
  geom_point(alpha = 0.5,
             color = &amp;quot;blue&amp;quot;) +
  labs(title = &amp;quot;XGBoost Model of Penguin Weight&amp;quot;,
       subtitle = &amp;quot;Bootstrap models can generate prediction intervals&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thedatadiary.net/blog/2022-03-14-introducing-workboots/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;4500&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This particular model may be in need of some tuning for better performance, but the important takeaway is that we were able to generate a prediction distribution for the model! This method works with other regression models as well — just create a workflow then let &lt;code&gt;{workboots}&lt;/code&gt; take care of the rest!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidymodel-resources&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tidymodel Resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tidymodels.org/start/&#34;&gt;Getting Started with Tidymodels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tmwr.org/&#34;&gt;Tidy Modeling with R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://juliasilge.com/blog/&#34;&gt;Julia Silge’s Blog&lt;/a&gt; provides use cases of tidymodels with weekly &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday&#34;&gt;#tidytuesday&lt;/a&gt; datasets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
